
image: docker:latest

# GitLab Build and Deploy to a Server via SSH
# https://codeburst.io/gitlab-build-and-push-to-a-server-via-ssh-6d27ca1bf7b4

variables:
  WORKDIR: /builds/analitico/
  BUILD_ANALITICO_IMAGE_URL: eu.gcr.io/analitico-api/analitico:$CI_COMMIT_SHA
  BUILD_ANALITICO_CLIENT_IMAGE_URL: eu.gcr.io/analitico-api/analitico-client:$CI_COMMIT_SHA
  BUILD_JUPYTER_IMAGE_URL: eu.gcr.io/analitico-api/analitico-jupyter:$CI_COMMIT_SHA 
  GIT_STRATEGY: none
  MOUNT_PATH: /mnt/analitico-drive
  WEBSITE_DEPLOYMENT_PATH: /mnt/analitico-drive/deployments/$CI_COMMIT_SHA
  
services:
- docker:dind

stages:
  - build
  - deploy-staging
  - live-tests
  - deploy-production

cache:
  paths:
    - pip-cache

build-and-test:
  stage: build
  script:
    ##
    ## Install dependecies
    ##

    - apk add git bash curl python
    - curl https://sdk.cloud.google.com > script.sh
    - chmod +x script.sh
    - ./script.sh --disable-prompts
    - export PATH=/root/google-cloud-sdk/bin:$PATH
    # install samba/cifs package for mounting the 
    # remote storage for the static website's files
    - apk add cifs-utils util-linux
    # install Node and Yarn for building the website
    - curl -sL https://deb.nodesource.com/setup_10.x | bash && apt-get install -y nodejs && curl -sS https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add - 
    - echo "deb https://dl.yarnpkg.com/debian/ stable main" | tee /etc/apt/sources.list.d/yarn.list
    - apt-get update && apt-get install yarn'

    
    ##
    ## Setup the environment
    ## 
    
    # cleanup
    - cd $WORKDIR
    - rm -rf $WORKDIR/*
    # clone with submodule 
    - echo "https://gionatamettifogo:$GITHUB_PULL_TOKEN@github.com/analitico/analitico.git" > /.git-credentials
    - echo "https://gionatamettifogo:$GITHUB_PULL_TOKEN@github.com/analitico/analitico-app.git " >> /.git-credentials
    - echo "https://gionatamettifogo:$GITHUB_PULL_TOKEN@github.com/analitico/analitico-sdk.git " >> /.git-credentials
    # save credentials to bypass login when fetching submodules
    - git config --global credential.helper 'store --file=/.git-credentials'
    # clone the source in /builds/analitico/analitico
    - git clone --recurse-submodules https://gionatamettifogo:$GITHUB_PULL_TOKEN@github.com/analitico/analitico.git 
    - cd analitico
    # check out corrent commit because repo may have gone further
    - git checkout --recurse-submodules $CI_COMMIT_SHA
    #Â go back
    - cd ..
    # clone secrets in /builds/analitico/analitico-ci
    - git clone https://gionatamettifogo:$GITHUB_PULL_TOKEN@github.com/analitico/analitico-ci.git 
    # remove credentials
    - rm /.git-credentials
    # append the Gihub commit sha in the environment script
    - echo export ANALITICO_COMMIT_SHA="$CI_COMMIT_SHA" >> analitico-ci/analitico-env.sh
    # authentication for Google Cloud Container Registry
    - gcloud -q auth activate-service-account --key-file ./analitico-ci/gcloud/analitico-api-service-account-key.json
    - gcloud -q auth configure-docker
    # mount analitico drive for website's static files
    - mount.cifs -o username=$ANALITICO_DRIVE_USERNAME,pass=$ANALITICO_DRIVE_PASSWORD,dir_mode=0755,file_mode=0644,noperm,uid=33,gid=33 //$ANALITICO_DRIVE_USERNAME.your-storagebox.de/$ANALITICO_DRIVE_USERNAME $MOUNT_PATH
    - mkdir -p $WEBSITE_DEPLOYMENT_PATH

    
    ##
    ## Build Analitico image
    ##

    - cd $WORKDIR
    - echo "$(date +'%T') - Build Analitico image"
    - cp ./analitico/serverless/templates/analitico/Dockerfile ./Dockerfile
    - docker build --no-cache --pull -t $BUILD_ANALITICO_IMAGE_URL -f Dockerfile .
    - echo "$(date +'%T') - Finished building analitico image"
    - docker push $BUILD_ANALITICO_IMAGE_URL
    - echo "$(date +'%T') - Copy Django static files to the storage"
    # extract django statics from the just built image 
    # and then save the files to storage
    - ANALITICO_IMAGE_NAME=analitico-$(date +%s)
    - docker create -it --name $ANALITICO_IMAGE_NAME $BUILD_ANALITICO_IMAGE_URL bash
    - docker cp $ANALITICO_IMAGE_NAME:/home/www/analitico/source/static $WEBSITE_DEPLOYMENT_PATH/static
    - docker rm -fv $ANALITICO_IMAGE_NAME
    - echo "$(date +'%T') - Finished pushing analitico image"

    ##
    ## Build Analitico Website
    ##

    - cd $WORKDIR
    - echo "$(date +'%T') - Build Analitico Website"
    # build 
    - BUILD_WEBSITE_PATH=$WORKDIR/analitico/app/applications/analitico
    - ./analitico/app/build-app.sh
    # save build to storage
    - cp -r $BUILD_WEBSITE_PATH/* $WEBSITE_DEPLOYMENT_PATH/
    - echo "$(date +'%T') - Finished building the app"
    
    ##
    ## Build Analitico-Client image
    ##

    - cd $WORKDIR
    - echo "$(date +'%T') - Build analitico-client image"
    - build_dir=$(mktemp -d)
    # dockerfile expects to find s24 in that path
    - mkdir $build_dir/libraries
    - cp -Rf ./analitico/source/s24 $build_dir/libraries
    - cp -Rf ./analitico/serverless/templates/analitico-client/* $build_dir/
    - cd $build_dir
    - docker build --no-cache --pull -t $BUILD_ANALITICO_CLIENT_IMAGE_URL -f Dockerfile .
    - echo "$(date +'%T') - Finished building analitico-client image"
    - docker push $BUILD_ANALITICO_CLIENT_IMAGE_URL
    - echo "$(date +'%T') - Finished pushing analitico-client image"
    # cleanup
    - rm -Rf $build_dir
    
    ## 
    ## Remove secrets and done
    ## 
    - rm -R -f analitico-ci
  only:
    - master

website-api-staging:
  stage: deploy-staging
  image: google/cloud-sdk:latest
  only:
    - master
  script:
    # deployment stage
    - STAGE=staging
    - git clone https://gionatamettifogo:$GITHUB_PULL_TOKEN@github.com/analitico/analitico-ci.git 
    # required by kubectl for committing the service on k8
    - export KUBECONFIG="./analitico-ci/k8/admin.conf"
    - yaml=`cat ./analitico-ci/k8/api-service-staging-template.yaml`
    - echo "${yaml/"{docker_image}"/$BUILD_ANALITICO_IMAGE_URL}" > api-service-staging-template.yaml
    - cat api-service-staging-template.yaml
    - kubectl apply --filename ./api-service-staging-template.yaml
    # wait deploy to complete
    - kubectl wait -n cloud kservice/website-staging --for=condition=Ready --timeout=32s
    # copy website's files to cloud storage 
    - mount.cifs -o username=$ANALITICO_DRIVE_USERNAME,pass=ANALITICO_DRIVE_PASSWORD,dir_mode=0755,file_mode=0644,noperm,uid=33,gid=33 //$ANALITICO_DRIVE_USERNAME.your-storagebox.de/$ANALITICO_DRIVE_USERNAME $MOUNT_PATH
    - cp -r $WEBSITE_DEPLOYMENT_PATH/* $MOUNT_PATH/$STAGE
    # cleanup files from deployments older then 7 days
    - find $MOUNT_PATH/$STAGE/* -mtime +7 -exec rm -rf {} \;
    - umount $MOUNT_PATH
  
website-api:
  stage: deploy-production
  image: google/cloud-sdk:latest
  when: manual
  only:
    - master
  script:
    # deployment stage
    - STAGE=production
    - git clone https://gionatamettifogo:$GITHUB_PULL_TOKEN@github.com/analitico/analitico-ci.git 
    # required by kubectl for committing the service on k8
    - export KUBECONFIG="./analitico-ci/k8/admin.conf"
    - yaml=`cat ./analitico-ci/k8/api-service-template.yaml`
    - echo "${yaml/"{docker_image}"/$BUILD_ANALITICO_IMAGE_URL}" > api-service-template.yaml
    - cat api-service-template.yaml
    - kubectl apply --filename ./api-service-template.yaml
    # wait deploy to complete
    - kubectl wait -n cloud kservice/website --for=condition=Ready --timeout=32s
    # copy website's files to cloud storage 
    - mount.cifs -o username=$ANALITICO_DRIVE_USERNAME,pass=ANALITICO_DRIVE_PASSWORD,dir_mode=0755,file_mode=0644,noperm,uid=33,gid=33 //$ANALITICO_DRIVE_USERNAME.your-storagebox.de/$ANALITICO_DRIVE_USERNAME $MOUNT_PATH
    - cp -r $WEBSITE_DEPLOYMENT_PATH/* $MOUNT_PATH/$STAGE
    # cleanup files from deployments older then 7 days
    - find $MOUNT_PATH/$STAGE/* -mtime +7 -exec rm -rf {} \;
    - umount $MOUNT_PATH

live-tests:
  stage: live-tests
  image: ubuntu:18.04
  only:
    - master
  before_script:
  ##
  ## Install ssh-agent if not already installed, it is required by Docker.
  ## (change apt-get to yum if you use an RPM-based image)
  ##
  - 'which ssh-agent || ( apt-get update -y && apt-get install openssh-client -y )'

  ##
  ## Run ssh-agent (inside the build environment)
  ##
  - eval $(ssh-agent -s)

  ##
  ## Add the SSH key stored in SSH_PRIVATE_KEY variable to the agent store
  ## We're using tr to fix line endings which makes ed25519 keys work
  ## without extra base64 encoding.
  ## https://gitlab.com/gitlab-examples/ssh-private-key/issues/1#note_48526556
  ##
  - mkdir -p ~/.ssh
  - echo "$STAGING_PRIVATE_KEY" | base64 -d -w0 | tr -d '\r' > ~/.ssh/id_rsa
  - chmod 600 ~/.ssh/id_rsa
  - ssh-add ~/.ssh/id_rsa

  # it creates a useless container "analitico-worker-keep-jupyter-image"
  # to keep the image "-jupyter" that is used for the papermill dockers
  # otherwise "docker image prune -f -a" will remove the image (because it has no containers associated)

  script:
    - ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no root@$STAGING_SERVER_NAME "export PATH=/root/google-cloud-sdk/bin:$PATH; gcloud -q auth activate-service-account --key-file /gcloud/analitico-api-service-account-key.json; gcloud -q auth configure-docker;
      docker pull ${BUILD_ANALITICO_IMAGE_URL}; 
      docker stop analitico-live-tests; 
      docker rm  analitico-live-tests; 
      docker run --name=analitico-live-tests --restart always -d -v /var/run/docker.sock:/var/run/docker.sock ${BUILD_ANALITICO_IMAGE_URL} ./scripts/live-tests.sh;"
