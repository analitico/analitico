{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_classification.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RNGwNhZFYDhE","colab_type":"text"},"source":["# Serverless Example\n","## PyTorch [CLASSIFICATION]"]},{"cell_type":"markdown","metadata":{"id":"NqWvcF2p5XWQ","colab_type":"text"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"XEOXLqSyT2Ap","colab_type":"code","outputId":"fba86276-675f-4334-f954-eae326ff2f1e","executionInfo":{"status":"ok","timestamp":1563133544620,"user_tz":-120,"elapsed":6049,"user":{"displayName":"Fabio Mardero","photoUrl":"","userId":"01769998706955373091"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Install some dependencies\n","!pip install torch\n","\n","\n","import time\n","import logging\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","\n","# Use CPU or GPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","torch.__version__"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.14.6)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'1.1.0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"lSK1CO-O_IdH","colab_type":"text"},"source":["### Load Database"]},{"cell_type":"code","metadata":{"id":"Ja3-ZEDT7kFL","colab_type":"code","colab":{}},"source":["iris = datasets.load_iris()\n","\n","X = iris.data.astype('float32')\n","y = iris.target.astype('int')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1N71slD65Eu4","colab_type":"text"},"source":["## Training Process"]},{"cell_type":"markdown","metadata":{"id":"tn50X6xw5IxJ","colab_type":"text"},"source":["### DataLoaders definition\n","Data Loader is a client function for the bulk import of data. It reads the contentent and divides it in batches. We divide the dataset into training e validation sets."]},{"cell_type":"code","metadata":{"id":"r0dWCplEjt-8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"e9ab2e91-bb7f-4164-d310-efa17b89e35a","executionInfo":{"status":"ok","timestamp":1563133544626,"user_tz":-120,"elapsed":5986,"user":{"displayName":"Fabio Mardero","photoUrl":"","userId":"01769998706955373091"}}},"source":["BATCH_SIZE = 8\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n","print('Training examples    : {:5d}'.format(len(X_train)))\n","print('Validation examples  : {:5d}'.format(len(X_valid)))\n","\n","train_ds = DataLoader(dataset=TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train)),\n","                      batch_size=BATCH_SIZE, \n","                      shuffle=True)\n","\n","valid_ds = DataLoader(dataset=TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid)),\n","                      batch_size=BATCH_SIZE, \n","                      shuffle=False)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Training examples    :   120\n","Validation examples  :    30\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1mHw7MnCo4tf","colab_type":"text"},"source":["### Model Definition\n","We define a simple neural network. In PyTorch we need to specify the input size (\"in_features\" parameter of the first layer)."]},{"cell_type":"code","metadata":{"id":"ddyvSCrbYRa9","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(in_features=4, out_features=5)\n","        self.fc2 = nn.Linear(5, 4)\n","        self.fc3 = nn.Linear(4, 3)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        return F.log_softmax(self.fc3(x), dim=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"grFBmZ4Eh0bc","colab_type":"code","colab":{}},"source":["model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"43Rksdr84_0D","colab_type":"text"},"source":["### Training\n","The model will give bad performances due to the lack of normalization of the inputs. We keep saving the model that gives the best performances during training."]},{"cell_type":"code","metadata":{"id":"_6ikPTPB9K5v","colab_type":"code","colab":{}},"source":["# Evaluation metric\n","# It is calculated as the mean \n","# of the metric through the batch\n","\n","def eval(data_loader, model):\n","    # Cumulative loss\n","    cum_loss = 0\n","    num_examples = 0\n","    \n","    for data, label in data_loader:\n","        data = data.to(device)\n","        label = label.to(device)\n","        num_examples += data.shape[0]\n","        \n","        y_pred = model(data)\n","        loss = F.nll_loss(y_pred, label)\n","        cum_loss += loss.item()\n","    return cum_loss/num_examples"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dwqQe1yPODtF","colab_type":"code","outputId":"2a09eb72-bd13-456f-c874-c7a6498f3747","executionInfo":{"status":"ok","timestamp":1563133545079,"user_tz":-120,"elapsed":6369,"user":{"displayName":"Fabio Mardero","photoUrl":"","userId":"01769998706955373091"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["EPOCHS = 10\n","MODEL_PATH = 'model'\n","\n","train_loss = []    \n","valid_loss = []\n","\n","# Time to train\n","for e in range(EPOCHS):\n","    tick = time.time()\n","    \n","    # Batch training\n","    model.train()\n","    for data, label in train_ds:\n","        data = data.to(device)\n","        label = label.to(device)\n","        \n","        # Backpropagation\n","        optimizer.zero_grad()\n","        y_pred = model(data)\n","        loss = F.nll_loss(y_pred, label)\n","        loss.backward()\n","        optimizer.step()\n","        \n","    # Training metrics\n","    train_loss.append(eval(train_ds, model))\n","    \n","    # Validation metrics\n","    valid_loss.append(eval(valid_ds, model))\n","    \n","    # Save the model if it reaches the best performances\n","    if valid_loss[-1] == min(valid_loss):\n","        torch.save(model, f'{MODEL_PATH}.pt')\n","    \n","    print('Epoch {:3d} [{:.2f} sec] - Training Loss: {:.4f} - Validation Loss: {:.4f}'.format(e+1, time.time()-tick, train_loss[e], valid_loss[e]))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Epoch   1 [0.05 sec] - Training Loss: 0.1314 - Validation Loss: 0.1401\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch   2 [0.03 sec] - Training Loss: 0.1137 - Validation Loss: 0.1232\n","Epoch   3 [0.02 sec] - Training Loss: 0.0867 - Validation Loss: 0.0953\n","Epoch   4 [0.02 sec] - Training Loss: 0.0781 - Validation Loss: 0.0857\n","Epoch   5 [0.03 sec] - Training Loss: 0.0734 - Validation Loss: 0.0807\n","Epoch   6 [0.02 sec] - Training Loss: 0.0702 - Validation Loss: 0.0770\n","Epoch   7 [0.03 sec] - Training Loss: 0.0686 - Validation Loss: 0.0754\n","Epoch   8 [0.02 sec] - Training Loss: 0.0666 - Validation Loss: 0.0730\n","Epoch   9 [0.03 sec] - Training Loss: 0.0657 - Validation Loss: 0.0722\n","Epoch  10 [0.03 sec] - Training Loss: 0.0654 - Validation Loss: 0.0695\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GQoRvmU25R7R","colab_type":"text"},"source":["## Testing Process\n","We simulate a test phase in which we only have a trained model saved in the current directory."]},{"cell_type":"markdown","metadata":{"id":"XdM_vArrFMA5","colab_type":"text"},"source":["### Blank Paper"]},{"cell_type":"code","metadata":{"id":"y0rRfJNeFHyx","colab_type":"code","colab":{}},"source":["# Lets put us in blank paper condition\n","del model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qv0rLJANeZcB","colab_type":"text"},"source":["### Prediction\n","Load the model and simulate to predict the whole iris dataset."]},{"cell_type":"code","metadata":{"id":"vJOQxX36FHce","colab_type":"code","outputId":"8f8b1d75-76d5-4c91-da3a-8da4a67cff53","executionInfo":{"status":"ok","timestamp":1563133545085,"user_tz":-120,"elapsed":6351,"user":{"displayName":"Fabio Mardero","photoUrl":"","userId":"01769998706955373091"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["logger = logging.getLogger('iris')\n","\n","\n","## Prediction \n","def handle(event, **kwargs):\n","    # If data is received as json convert to pandas\n","    event = event['data'] if 'data' in event else event\n","    if not isinstance(event, pd.DataFrame):\n","        event = pd.DataFrame.from_dict(event, orient='columns')\n","\n","    # Convert to NDArray\n","    data = torch.from_numpy(event.values.astype('float32'))\n","    \n","    # Retrieve model from disk and use it for predictions\n","    model = torch.load(f'{MODEL_PATH}.pt')\n","    model.eval()\n","    \n","    # Target format convertion\n","    target_dict = {0: 'setosa', 1: 'versicolor', 2:'virginica'}\n","    to_target = np.vectorize(lambda x: target_dict[x])\n","    \n","    return to_target(np.argmax(model(data).detach().numpy(), axis=1)).tolist()\n","\n","## Testing and liveness check\n","def test(data, **kwargs):\n","    pred = handle(data)\n","\n","    logger.warning(f\"predicted: {pred}\")\n","    \n","    return True\n","\n","\n","test(iris.data)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  import sys\n","predicted: ['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'setosa', 'setosa', 'versicolor', 'versicolor', 'virginica', 'versicolor', 'versicolor', 'setosa', 'virginica', 'versicolor', 'versicolor', 'setosa', 'versicolor', 'versicolor', 'versicolor', 'setosa', 'versicolor', 'versicolor', 'versicolor', 'virginica', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'versicolor', 'setosa', 'versicolor', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'versicolor', 'virginica', 'virginica', 'virginica', 'virginica', 'versicolor', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'versicolor', 'versicolor', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'virginica', 'versicolor', 'versicolor', 'virginica', 'versicolor', 'virginica', 'virginica', 'virginica', 'versicolor', 'virginica', 'virginica', 'virginica', 'virginica']\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":9}]}]}