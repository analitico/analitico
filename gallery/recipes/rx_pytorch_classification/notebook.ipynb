{"cells":[{"cell_type":"markdown","source":["# 101: PyTorch classification\n","\n","From Machine Learning model to scalable deployment with Analitico.\n","\n","Read the full documentation in the [Documents](https://analitico.ai/app/recipes/rx_pytorch_classification/markdown/readme.md) page."],"metadata":{"colab_type":"text","id":"RNGwNhZFYDhE","papermill":{"duration":0.01173,"end_time":"2019-10-12T17:58:07.232662","exception":false,"start_time":"2019-10-12T17:58:07.220932","status":"completed"},"tags":[]}},{"cell_type":"code","source":["# Load some dependencies\n","!pip install -q torch"],"outputs":[],"execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":68},"colab_type":"code","executionInfo":{"elapsed":6049,"status":"ok","timestamp":1563133544620,"user":{"displayName":"Fabio Mardero","photoUrl":"","userId":"01769998706955373091"},"user_tz":-120},"id":"XEOXLqSyT2Ap","outputId":"fba86276-675f-4334-f954-eae326ff2f1e","papermill":{"duration":1.317353,"end_time":"2019-10-12T17:58:08.558198","exception":false,"start_time":"2019-10-12T17:58:07.240845","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":["## Model\n","We define a simple neural network with PyTorch."],"metadata":{"papermill":{"duration":0.014791,"end_time":"2019-10-12T17:58:08.589398","exception":false,"start_time":"2019-10-12T17:58:08.574607","status":"completed"},"tags":[]}},{"cell_type":"code","source":["import logging\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","\n","import analitico\n","\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","# You can import your own library.\n","# Here we import our custom model.\n","# See: https://analitico.ai/app/recipes/rx_pytorch_classification/files/Net.py\n","from Net import Net\n","\n","# Use CPU or GPU\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Load sample dataset\n","iris = datasets.load_iris()\n","\n","X = iris.data.astype('float32')\n","y = iris.target.astype('int')\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n","\n","# Create model, optimizer and loss function\n","model = Net().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()\n","epochs = 100\n","\n","# Train the model without dataloader\n","X_train_var, y_train_var = Variable(torch.from_numpy(X_train)).float(), Variable(torch.from_numpy(y_train)).long()\n","\n","min_loss = 2.0\n","for epoch in range(epochs):\n","    y_pred = model(X_train_var)\n","    loss = loss_fn(y_pred, y_train_var)\n","\n","    # Zero gradients\n","    optimizer.zero_grad()\n","    # Gradients\n","    loss.backward()\n","    # Update\n","    optimizer.step()\n","    \n","    # Save the best model\n","    if loss.item() < min_loss:\n","        min_loss = loss.item()\n","        torch.save(model, 'pytorch_classifer_model.pt')\n","\n","print(\"Training loss: \", min_loss)\n","\n","# Test the model accuracy\n","X_test_var = Variable(torch.from_numpy(X_test)).float()\n","pred = model(X_test_var)\n","pred = pred.detach().numpy()\n","\n","score = accuracy_score(y_test, np.argmax(pred, axis=1))\n","print (\"Model accuracy: {:.2%}\".format(score))\n","\n","# Save metrics for later training evaluation\n","analitico.set_metric(\"loss\", str(min_loss), \"Loss\", \"best-model\", \"Best model\")\n","analitico.set_metric(\"accuracy\", str(score), \"Accuracy\", \"best-model\")"],"outputs":[{"output_type":"stream","name":"stdout","text":["Training loss:  0.570770263671875\n","Model accuracy: 96.67%\n"]}],"execution_count":5,"metadata":{"papermill":{"duration":0.956348,"end_time":"2019-10-12T17:58:09.564659","exception":true,"start_time":"2019-10-12T17:58:08.608311","status":"failed"},"tags":[]}},{"cell_type":"markdown","source":["## Analitico serverless handler\n","\n","The serverless endpoint is set to call the `handle(event, **kwargs)` method with a set of data required by the model.\n","Here we load the model, execute the prediction with the input data and return the result."],"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":["# This cell is executed in a different context.\n","# All imports are declared here and all the dependecies \n","# it needs to run are specified in the requirements.txt file\n","# https://analitico.ai/app/recipes/rx_pytorch_classification/files/requirements.txt.\n","\n","import json\n","import numpy as np\n","import torch\n","from torch.autograd import Variable\n","\n","# Import our custom model.\n","# See: https://analitico.ai/app/recipes/rx_pytorch_classification/files/Net.py\n","from Net import Net\n","\n","# Retrieve the model here to be used between requests\n","model = torch.load(\"pytorch_classifer_model.pt\")\n","model.eval()\n","\n","def handle(event, **kwargs):\n","    \"\"\" Method called by the serverless endpoint url with the data for prediction \"\"\"\n","    \n","    event = np.array([event])\n","\n","    # Convert to NDArray\n","    data = Variable(torch.from_numpy(event)).float()\n","    \n","    prediction = model(data).detach().numpy()\n","    \n","    class_id = np.argmax(prediction)\n","    \n","    return { \"class_id\": int(class_id) }\n","\n","def test(**kwargs):\n","    \"\"\" Test method can be called by Analitico to verify that model is working \"\"\"\n","    \n","    # sepal_length, sepal_width, petal_length, petal_width\n","    data = [6.3, 2.3, 4.4, 1.3]\n","        \n","    results = handle(data)\n","    print(json.dumps(results, indent=2))\n","  \n","    # we expect our prediction to be the iris Versicolour (class 1)\n","    print(\"\\nTest passed: \")\n","    return results[\"class_id\"] == 1"],"outputs":[],"execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105},"colab_type":"code","executionInfo":{"elapsed":6351,"status":"ok","timestamp":1563133545085,"user":{"displayName":"Fabio Mardero","photoUrl":"","userId":"01769998706955373091"},"user_tz":-120},"id":"vJOQxX36FHce","outputId":"8f8b1d75-76d5-4c91-da3a-8da4a67cff53","papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"markdown","source":["## Test the endpoint\n","\n","Finally, let's test the endpoint with sample data."],"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":["test()"],"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"class_id\": 1\n","}\n","\n","Test passed: \n"]},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":["True"]},"metadata":{}}],"execution_count":7,"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}}],"metadata":{"colab":{"collapsed_sections":[],"name":"pytorch_classification.ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"papermill":{"output_path":"/mnt/analitico-drive/recipes/rx_pytorch_classification/notebook.ipynb","start_time":"2019-10-12T17:58:06.599226","parameters":{},"environment_variables":{},"exception":true,"end_time":"2019-10-12T17:58:10.073769","duration":3.474543,"version":"1.0.1","input_path":"/mnt/analitico-drive/recipes/rx_pytorch_classification/notebook.ipynb"}},"nbformat":4,"nbformat_minor":1}