{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RNGwNhZFYDhE",
        "papermill": {
          "duration": 0.011646,
          "end_time": "2019-10-14T07:15:43.807694",
          "exception": false,
          "start_time": "2019-10-14T07:15:43.796048",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# 101: PyTorch classifier\n",
        "\n",
        "From Machine Learning model to scalable deployment with Analitico.\n",
        "\n",
        "Read the full documentation in the [Documents](https://analitico.ai/app/recipes/rx_pytorch_classification/markdown/readme.md) page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 6049,
          "status": "ok",
          "timestamp": 1563133544620,
          "user": {
            "displayName": "Fabio Mardero",
            "photoUrl": "",
            "userId": "01769998706955373091"
          },
          "user_tz": -120
        },
        "id": "XEOXLqSyT2Ap",
        "outputId": "fba86276-675f-4334-f954-eae326ff2f1e",
        "papermill": {
          "duration": 1.377811,
          "end_time": "2019-10-14T07:15:45.193654",
          "exception": false,
          "start_time": "2019-10-14T07:15:43.815843",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Load some dependencies\n",
        "!pip install -q torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.013129,
          "end_time": "2019-10-14T07:15:45.224951",
          "exception": false,
          "start_time": "2019-10-14T07:15:45.211822",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Model\n",
        "We define a simple neural network with PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "papermill": {
          "duration": 2.21351,
          "end_time": "2019-10-14T07:15:47.451395",
          "exception": false,
          "start_time": "2019-10-14T07:15:45.237885",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training loss:  0.5694853067398071\n",
            "Model accuracy: 96.67%\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "import analitico\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# You can import your own library.\n",
        "# Here we import our custom model.\n",
        "# See: https://analitico.ai/app/recipes/rx_pytorch_classification/files/Net.py\n",
        "from Net import Net\n",
        "\n",
        "# Use CPU or GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load sample dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data.astype('float32')\n",
        "y = iris.target.astype('int')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "\n",
        "# Create model, optimizer and loss function\n",
        "model = Net().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "epochs = 100\n",
        "\n",
        "# Train the model without dataloader\n",
        "X_train_var, y_train_var = Variable(torch.from_numpy(X_train)).float(), Variable(torch.from_numpy(y_train)).long()\n",
        "\n",
        "min_loss = 2.0\n",
        "for epoch in range(epochs):\n",
        "    y_pred = model(X_train_var)\n",
        "    loss = loss_fn(y_pred, y_train_var)\n",
        "\n",
        "    # Zero gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Gradients\n",
        "    loss.backward()\n",
        "    # Update\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Save the best model\n",
        "    if loss.item() < min_loss:\n",
        "        min_loss = loss.item()\n",
        "        torch.save(model, 'pytorch_classifer_model.pt')\n",
        "\n",
        "print(\"Training loss: \", min_loss)\n",
        "\n",
        "# Test the model accuracy\n",
        "X_test_var = Variable(torch.from_numpy(X_test)).float()\n",
        "pred = model(X_test_var)\n",
        "pred = pred.detach().numpy()\n",
        "\n",
        "score = accuracy_score(y_test, np.argmax(pred, axis=1))\n",
        "print (\"Model accuracy: {:.2%}\".format(score))\n",
        "\n",
        "# Save metrics for later training evaluation\n",
        "analitico.set_metric(\"loss\", str(min_loss), \"Loss\", \"best-model\", \"Best model\")\n",
        "analitico.set_metric(\"accuracy\", str(score), \"Accuracy\", \"best-model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.008138,
          "end_time": "2019-10-14T07:15:47.469421",
          "exception": false,
          "start_time": "2019-10-14T07:15:47.461283",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Analitico serverless handler\n",
        "\n",
        "The serverless endpoint is set to call the `handle(event, **kwargs)` method with a set of data required by the model.\n",
        "Here we load the model, execute the prediction with the input data and return the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "colab_type": "code",
        "executionInfo": {
          "elapsed": 6351,
          "status": "ok",
          "timestamp": 1563133545085,
          "user": {
            "displayName": "Fabio Mardero",
            "photoUrl": "",
            "userId": "01769998706955373091"
          },
          "user_tz": -120
        },
        "id": "vJOQxX36FHce",
        "outputId": "8f8b1d75-76d5-4c91-da3a-8da4a67cff53",
        "papermill": {
          "duration": 0.021528,
          "end_time": "2019-10-14T07:15:47.498839",
          "exception": false,
          "start_time": "2019-10-14T07:15:47.477311",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# This cell is executed in a different context.\n",
        "# All imports are declared here and all the dependecies \n",
        "# it needs to run are specified in the requirements.txt file\n",
        "# (see: https://analitico.ai/app/recipes/rx_pytorch_classification/files/requirements.txt).\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Import our custom model.\n",
        "# See: https://analitico.ai/app/recipes/rx_pytorch_classification/files/Net.py\n",
        "from Net import Net\n",
        "\n",
        "# Retrieve the model here to be used between requests\n",
        "model = torch.load(\"pytorch_classifer_model.pt\")\n",
        "model.eval()\n",
        "\n",
        "def handle(event, **kwargs):\n",
        "    \"\"\" Method called by the serverless endpoint url with the data for prediction \"\"\"\n",
        "    \n",
        "    event = np.array([event])\n",
        "\n",
        "    # Convert to NDArray\n",
        "    data = Variable(torch.from_numpy(event)).float()\n",
        "    \n",
        "    prediction = model(data).detach().numpy()\n",
        "    \n",
        "    class_id = np.argmax(prediction)\n",
        "    \n",
        "    return { \"class_id\": int(class_id) }\n",
        "\n",
        "def test(**kwargs):\n",
        "    \"\"\" Test method can be called by Analitico to verify that model is working \"\"\"\n",
        "    \n",
        "    # sepal_length, sepal_width, petal_length, petal_width\n",
        "    data = [6.3, 2.3, 4.4, 1.3]\n",
        "        \n",
        "    results = handle(data)\n",
        "    print(json.dumps(results, indent=2))\n",
        "  \n",
        "    # we expect our prediction to be the iris Versicolour (class 1)\n",
        "    print(\"\\nTest passed: \")\n",
        "    return results[\"class_id\"] == 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.008781,
          "end_time": "2019-10-14T07:15:47.516124",
          "exception": false,
          "start_time": "2019-10-14T07:15:47.507343",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Test the endpoint\n",
        "\n",
        "Finally, let's test the endpoint with sample data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "papermill": {
          "duration": 0.037093,
          "end_time": "2019-10-14T07:15:47.562625",
          "exception": false,
          "start_time": "2019-10-14T07:15:47.525532",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"class_id\": 1\n",
            "}\n",
            "\n",
            "Test passed: \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pytorch_classification.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "papermill": {
      "duration": 4.835839,
      "end_time": "2019-10-14T07:15:47.989094",
      "environment_variables": {},
      "exception": null,
      "input_path": "/mnt/analitico-drive/recipes/rx_pytorch_classification/notebook.ipynb",
      "output_path": "/mnt/analitico-drive/recipes/rx_pytorch_classification/notebook.ipynb",
      "parameters": {},
      "start_time": "2019-10-14T07:15:43.153255",
      "version": "1.0.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}